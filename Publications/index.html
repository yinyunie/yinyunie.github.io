<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Welcome to Yinyu's Personal Page</title><meta name="author" content="Yinyu Nie"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 4.2.1"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Welcome to Yinyu's Personal Page</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/"> Home</a></li><li class="menus_item"><a class="site-page" href="/Publications"> Publications</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/me.jpg" onerror="this.onerror=null;this.src='/img/me.jpg'" alt="avatar"></div><div class="author-discrip"><h3>Yinyu Nie</h3><p class="author-bio">Snap Inc. | Noah`s Ark Lab @ Huawei | Visual Computing &amp; AI Lab @ TUM</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="https://twitter.com/yinyu_nie" target="_blank"><i class="fab fa-twitter" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://github.com/yinyunie" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://www.linkedin.com/in/yinyu-nie-335499151/" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="mailto:nieyinyu@gmail.com" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="https://scholar.google.com/citations?user=_5v1obAAAAAJ" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li><li><a class="e-social-link" href="https://orcid.org/0000-0001-7023-6797" target="_blank"><i class="fab fa-orcid" aria-hidden="true"></i><span>ORCID</span></a></li></ul></div><a class="cv-links" href="/attaches/Yinyu_CV.pdf" target="_blank"><i class="fas fa-file-pdf" aria-hidden="true"><span>CV</span></i></a></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title"></h2><article><span style="font-family:serif;">

<h3 id="Main-Publications"><a href="#Main-Publications" class="headerlink" title="Main Publications"></a>Main Publications</h3><p><img align="left" src="/img/Publications/dashgaussian.jpg" width="180" height="125"> DashGaussian: Optimizing 3D Gaussian Splatting in 200 Seconds<br>Publication: <strong>CVPR2025 (Highlight)</strong> [<a href="https://arxiv.org/abs/2503.18402" target="_blank" rel="noopener">pdf</a>] [<a href="https://dashgaussian.github.io/" target="_blank" rel="noopener">project</a>]<br>Authors: Youyu Chen, Junjun Jiang, Kui Jiang, Xiao Tang, Zhihao Li, Xianming Liu, <strong>Yinyu Nie</strong><br>&nbsp;</p>
<p><img align="left" src="/img/Publications/siggraph_asia2024.png" width="180" height="125"> GarVerseLOD: High-Fidelity 3D Garment Reconstruction from a Single In-the-Wild Image using a Dataset with Levels of Details<br>Publication: <strong>SIGGRAPH Asia 2024</strong> (Journal Track) [<a href="https://arxiv.org/abs/2411.03047" target="_blank" rel="noopener">pdf</a>] [<a href="https://garverselod.github.io/" target="_blank" rel="noopener">project</a>][<a href="https://github.com/zhongjinluo/GarVerseLOD" target="_blank" rel="noopener">code</a>]<br>Authors: Zhongjin Luo, Haolin Liu, Chenghong Li, Wanghao Du, Zirong Jin, Wanhu Sun, <strong>Yinyu Nie</strong>, Weikai Chen, Xiaoguang Han<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/mesh2nerf.jpg" width="150" height="85"> Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation<br>Publication: <strong>ECCV 2024</strong> [<a href="https://arxiv.org/abs/2403.19319" target="_blank" rel="noopener">pdf</a>] [<a href="https://terencecyj.github.io/projects/Mesh2NeRF/" target="_blank" rel="noopener">project</a>][<a href="https://terencecyj.github.io/projects/Mesh2NeRF/" target="_blank" rel="noopener">code</a>]<br>Authors: Yujin Chen, <strong>Yinyu Nie</strong>, Benjamin Ummenhofer, Reiner Birkl, Michael Paulitsch, Matthias Müller, Matthias Nießner<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/headgas.png" width="150" height="85"> HeadGaS: Real-Time Animatable Head Avatars via 3D Gaussian Splatting<br>Publication: <strong>ECCV 2024</strong> [<a href="https://arxiv.org/abs/2312.02902" target="_blank" rel="noopener">pdf</a>]<br>Authors: Helisa Dhamo, <strong>Yinyu Nie</strong>, Arthur Moreau, Jifei Song, Richard Shaw, Yiren Zhou, Eduardo Pérez-Pellitero<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/LASA.png" width="150" height="85"> LASA: Instance Reconstruction from Real Scans using A Large-scale Aligned Shape Annotation Dataset<br>Publication: <strong>CVPR 2024</strong> [<a href="https://arxiv.org/abs/2312.12418" target="_blank" rel="noopener">pdf</a>] [<a href="https://gap-lab-cuhk-sz.github.io/LASA/" target="_blank" rel="noopener">project</a>][<a href="https://github.com/GAP-LAB-CUHK-SZ/LASA" target="_blank" rel="noopener">code</a>]<br>Authors: Haolin Liu, Chongjie Ye, <strong>Yinyu Nie</strong>, Yingfan He, Xiaoguang Han<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/dphms.png" width="150" height="85"> DPHMs: Diffusion Parametric Head Models for Depth-based Tracking<br>Publication: <strong>CVPR 2024</strong> [<a href="https://arxiv.org/abs/2312.01068" target="_blank" rel="noopener">pdf</a>] [<a href="https://tangjiapeng.github.io/projects/DPHMs/" target="_blank" rel="noopener">project</a>] [<a href="https://youtu.be/w_EJ5LDJ7T4?si=6v5dQ3H-LUd50381" target="_blank" rel="noopener">video</a>][<a href="https://github.com/tangjiapeng/DPHMs" target="_blank" rel="noopener">code</a>]<br>Authors: Jiapeng Tang, Angela Dai, <strong>Yinyu Nie</strong>, Lev Markhasin, Justus Thies, Matthias Nießner<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/diffuscene.png" width="150" height="85"> DiffuScene: Scene Graph Denoising Diffusion Probabilistic Model for Generative Indoor Scene Synthesis<br>Publication: <strong>CVPR 2024</strong> [<a href="https://arxiv.org/abs/2303.14207" target="_blank" rel="noopener">pdf</a>] [<a href="https://tangjiapeng.github.io/projects/DiffuScene/" target="_blank" rel="noopener">project</a>] [<a href="https://www.youtube.com/embed/VkBey2ZHA6E" target="_blank" rel="noopener">video</a>][<a href="https://github.com/tangjiapeng/DiffuScene" target="_blank" rel="noopener">code</a>]<br>Authors: Jiapeng Tang, <strong>Yinyu Nie</strong>, Lev Markhasin, Angela Dai, Justus Thies, Matthias Nießner<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/cvpr23.jpg" width="150" height="85"> Learning 3D Scene Priors with 2D Supervision<br>Publication: <strong>CVPR 2023</strong> [<a href="https://arxiv.org/abs/2211.14157" target="_blank" rel="noopener">pdf</a>][<a href="https://yinyunie.github.io/sceneprior-page/" target="_blank" rel="noopener">project</a>] [<a href="https://www.youtube.com/watch?v=YT7MEdygRoY" target="_blank" rel="noopener">video</a>][<a href="https://github.com/yinyunie/ScenePriors" target="_blank" rel="noopener">code</a>]<br>Authors: <strong>Yinyu Nie</strong>, Angela Dai, Xiaoguang Han, Matthias Nießner<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/cvpr23_xy.png" width="150" height="85"> NerVE: Neural Volumetric Edges for Parametric Edge Curve Extraction from Point Cloud<br>Publication: <strong>CVPR 2023</strong> [<a href="https://arxiv.org/abs/2303.16465" target="_blank" rel="noopener">pdf</a>] [<a href="https://dongdu3.github.io/projects/2023/NerVE/" target="_blank" rel="noopener">project</a>] [<a href="https://www.youtube.com/watch?v=tAwC23uybTM" target="_blank" rel="noopener">video</a>]<br>Authors: Xiangyu Zhu, Dong Du, Weikai Chen, Zhiyou Zhao, <strong>Yinyu Nie</strong>, Xiaoguang Han<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/neurips2022.png" width="150" height="109.1"> PatchComplete: Learning Multi-Resolution Patch Priors for 3D Shape Completion on Unseen Categories<br>Publication: <strong>NeurIPS 2022</strong> [<a href="https://arxiv.org/abs/2206.04916" target="_blank" rel="noopener">pdf</a>] [<a href="https://yuchenrao.github.io/projects/patchComplete/patchComplete.html" target="_blank" rel="noopener">project</a>] [<a href="https://www.youtube.com/watch?v=Ch1rvw2D_Kc" target="_blank" rel="noopener">video</a>]<br>Authors: Yuchen Rao, <strong>Yinyu Nie</strong>, Angela Dai (2022)<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/eccv2022.jpg" width="150" height="109.1"> Pose2Room: Understanding 3D Scenes from Human Activities<br>Publication: <strong>ECCV 2022</strong> [<a href="https://arxiv.org/abs/2112.03030" target="_blank" rel="noopener">pdf</a>][<a href="https://yinyunie.github.io/pose2room-page/" target="_blank" rel="noopener">project</a>] [<a href="https://youtu.be/MFfKTcvbM5o" target="_blank" rel="noopener">video</a>][<a href="https://github.com/yinyunie/pose2room" target="_blank" rel="noopener">code</a>]<br>Authors: <strong>Yinyu Nie</strong>, Angela Dai, Xiaoguang Han, Matthias Nießner (2022)<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/MEPCN_iccv21.png" width="150" height="109.1"> ME-PCN: Point Completion Conditioned on Mask Emptiness<br>Publication: <strong>ICCV 2021</strong> [<a href="https://arxiv.org/abs/2108.08187" target="_blank" rel="noopener">pdf</a>]<br>Authors: Bingchen Gong, <strong>Yinyu Nie</strong>, Yiqun Lin, Xiaoguang Han, Yizhou Yu (2021)<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/miccai21.png" width="150" height="109.1"> Surgical Instruction Generation with Transformers<br>Publication: <strong>MICCAI 2021</strong> [<a href="https://arxiv.org/abs/2107.06964" target="_blank" rel="noopener">pdf</a>]<br>Authors: Jinglu Zhang, <strong>Yinyu Nie</strong>, Jian Chang, Jian Jun Zhang (2021)<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/cvpr2021.jpg" width="150" height="109.1"> RfD-Net: Point Scene Understanding by Semantic Instance Reconstruction<br>Publication: <strong>CVPR 2021</strong> [<a href="https://arxiv.org/abs/2011.14744" target="_blank" rel="noopener">pdf</a>] [<a href="https://yinyunie.github.io/RfDNet-Page/" target="_blank" rel="noopener">project</a>] [<a href="https://github.com/yinyunie/RfDNet" target="_blank" rel="noopener">code</a>] [<a href="https://www.youtube.com/watch?v=RHHFC2UaZtQ" target="_blank" rel="noopener">video</a>]<br>Authors: <strong>Yinyu Nie</strong>, Ji Hou, Xiaoguang Han, Matthias Nießner (2021)<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/cgf2021.jpg" width="150" height="109.1"> Learning Part Generation and Assembly for Sketching Man‐Made Objects<br>Publication: <strong>CGF 2021</strong> [<a href="https://onlinelibrary.wiley.com/doi/epdf/10.1111/cgf.14184" target="_blank" rel="noopener">pdf</a>]<br>Authors: Dong Du, Heming Zhu, <strong>Yinyu Nie</strong>, Xiaoguang Han, Shuguang Cui, Yizhou Yu, Ligang Liu (2021)<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/neurips2020.png" width="150" height="109.1"> Skeleton-bridged Point Completion: From Global Inference to Local Adjustment<br>Publication: <strong>NeurIPS 2020</strong> [<a href="https://arxiv.org/abs/2010.07428" target="_blank" rel="noopener">pdf</a>] [<a href="https://yinyunie.github.io/SKPCN-page/" target="_blank" rel="noopener">project</a>]<br>Authors: <strong>Yinyu Nie</strong>, Yiqun Lin, Xiaoguang Han, Shihui Guo, Jian Chang, Shuguang Cui, Jian Jun Zhang (2020)<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/miccai2020.jpg" width="150" height="109.1"> Symmetric Dilated Convolution for Surgical Gesture Recognition<br>Publication: <strong>MICCAI 2020</strong> [<a href="https://arxiv.org/abs/2007.06373" target="_blank" rel="noopener">pdf</a>]<br>Authors: Jinglu Zhang, <strong>Yinyu Nie</strong>, Yao Lyu, Hailin Li, Jian Chang, Xiaosong Yang, Jian J Zhang (2020)<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/cvpr2020.jpg" width="150" height="109.1"> Total3DUnderstanding: Joint Layout, Object Pose and Mesh Reconstruction for Indoor Scenes from a Single Image<br>Publication: <strong>CVPR 2020 / Award nominee (oral presentation)</strong> [<a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Nie_Total3DUnderstanding_Joint_Layout_Object_Pose_and_Mesh_Reconstruction_for_Indoor_CVPR_2020_paper.pdf" target="_blank" rel="noopener">pdf</a>][<a href="http://openaccess.thecvf.com/content_CVPR_2020/supplemental/Nie_Total3DUnderstanding_Joint_Layout_CVPR_2020_supplemental.pdf" target="_blank" rel="noopener">supplemental</a>][<a href="https://yinyunie.github.io/Total3D/" target="_blank" rel="noopener">project</a>][<a href="https://www.youtube.com/watch?v=tq7jBhfdszI&t" target="_blank" rel="noopener">Talk</a>][<a href="https://github.com/yinyunie/Total3DUnderstanding" target="_blank" rel="noopener">code</a>]<br>Authors: <strong>Yinyu Nie</strong>, Xiaoguang Han, Shihui Guo, Yujian Zheng, Jian Chang, Jian Jun Zhang (2020)<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/PR2020.png" width="150" height="109.1"> Shallow2Deep: Indoor scene modeling by single image understanding<br>Publication: <strong>Pattern Recognition</strong>, 103, p.107271. [<a href="https://arxiv.org/abs/2002.09790" target="_blank" rel="noopener">pdf</a>]<br>Authors: <strong>Yinyu Nie</strong>, Shihui Guo, Jian Chang, Xiaoguang Han, Jiahui Huang, Shi-Min Hu, Jian Jun Zhang (2020)<br>&nbsp;</p>
<p><img align="left" src="/img/Publications/VSD2018.png" width="150" height="109.1"> A data-driven dynamics simulation framework for railway vehicles<br>Publication: <strong>Vehicle system dynamics</strong>, 56(3), pp.406-427. [<a href="http://eprints.bournemouth.ac.uk/30123/3/Data-driven%20dynamics%20simulation%20for%20railway%20vehicles.v1.pdf" target="_blank" rel="noopener">pdf</a>]<br>Authors: <strong>Yinyu Nie</strong>, Zhao Tang, Fengjia Liu, Jian Chang, Jian Jun Zhang (2018)<br>&nbsp;<br></span></p>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/"> Home</a></li><li class="nav_item"><a class="nav-page" href="/Publications"> Publications</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2021 - 2025 by Yinyu Nie</div><div class="theme-info">Powered by <a href="https://hexo.io" target="_blank" rel="nofollow noopener">Hexo</a> & <a href="https://github.com/PhosphorW/hexo-theme-academia" target="_blank" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>